{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYTjDEEbOd6R"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KAj35eC3Mx24",
        "outputId": "b7432ce7-5ee4-449c-a611-3651dc41555f"
      },
      "outputs": [],
      "source": [
        " !pip install transformers\n",
        " !pip install trafilatura\n",
        " !pip install wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJCMtEqdP1BZ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YPQpp5J1dsdE"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"henryk/bert-base-multilingual-cased-finetuned-polish-squad2\",\n",
        "    tokenizer=\"henryk/bert-base-multilingual-cased-finetuned-polish-squad2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JWWAMMpZOJAk"
      },
      "outputs": [],
      "source": [
        "from googlesearch import search\n",
        "from typing import List\n",
        "\n",
        "import requests\n",
        "import trafilatura\n",
        "import wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWVH-S6OP3M-"
      },
      "source": [
        "## Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EXpZgDq3M7FR"
      },
      "outputs": [],
      "source": [
        "def get_urls(query: str) -> List[str]:\n",
        "    \"\"\"Get sets of urls for given query, visit them and check for duplicates\"\"\"\n",
        "    urls = list(search(query, tld='com', lang=\"pl\",\n",
        "                start=0, stop=3, pause=1.0))\n",
        "    urls = [url for url in urls if \"#\" not in url]\n",
        "    seen_urls = set()\n",
        "    res_urls = []\n",
        "    for url in urls:\n",
        "        if url[:20] not in seen_urls:\n",
        "            seen_urls.add(url[:20])\n",
        "            res_urls.append(url)\n",
        "    return res_urls\n",
        "\n",
        "\n",
        "def get_context(url: str) -> str:\n",
        "    \"\"\"Visit url and get some text present there.\n",
        "    The size of the context is limited to 500 signs since the time of execution\n",
        "    of one question was too long.\n",
        "    \"\"\"\n",
        "    wikipedia.set_lang(\"pl\")\n",
        "    if \"wikipedia\" in url and \"wikimedia\" not in url:\n",
        "        r = requests.get(url)\n",
        "        html = r.text\n",
        "        title = html[html.find('<title>') + 7: html.find('</title>')][:-32]\n",
        "        wiki_page = wikipedia.page(title)\n",
        "        context = wiki_page.content\n",
        "    else:\n",
        "        downloaded = trafilatura.fetch_url(url)\n",
        "        context = trafilatura.extract(downloaded)\n",
        "    return context[:500]\n",
        "\n",
        "\n",
        "def find_answer(question: str) -> str:\n",
        "    \"\"\"Find answer to given question using context from websites and Henryk\n",
        "    model for finding answer in chosen text.\n",
        "    \"\"\"\n",
        "    urls = get_urls(question)\n",
        "    answers = []\n",
        "    seen_answers = set()\n",
        "    for url in urls:\n",
        "        context = get_context(url)\n",
        "        if context:\n",
        "            ans = qa_pipeline({\"context\": context, \"question\": question})\n",
        "            if ans['answer'] not in seen_answers:\n",
        "                seen_answers.add(ans['answer'])\n",
        "            else:\n",
        "                return determine_best_answer(answers)\n",
        "            answers.append(ans)\n",
        "    return determine_best_answer(answers)\n",
        "\n",
        "\n",
        "def determine_best_answer(answers: List[str]) -> str:\n",
        "    \"\"\"Find answer with the largest score.\"\"\"\n",
        "    return (max(answers, key=lambda x: x['score']))['answer']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qKXM81LqM3AV",
        "outputId": "9bf3aef7-9075-480e-edc0-285c3f62443d"
      },
      "outputs": [],
      "source": [
        "find_answer(\"Co robi Robert Makłowicz?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ryF69wEpIuMB",
        "outputId": "02d998ad-9907-40fc-b1c8-6fbe399f035c"
      },
      "outputs": [],
      "source": [
        "find_answer(\"Co jest stolicą Polski?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "question_answerer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
