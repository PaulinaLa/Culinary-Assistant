{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeThTOxyXEhT"
      },
      "source": [
        "# Prerequisities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM4DaKZxXgFB",
        "outputId": "57f8edfc-d803-4869-ed45-3440e7119ec3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "B_Ltf7S4ayj-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from typing import Dict, List, Tuple, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kxzsWCr9pCF2"
      },
      "outputs": [],
      "source": [
        "# main path to your data folder\n",
        "main_path = 'gdrive/MyDrive/bot/data'\n",
        "\n",
        "# path to recipes saved as json file\n",
        "recipes_path = join(main_path, 'recipes/recipes.json')\n",
        "\n",
        "# path to vectors representing recipes ingredients\n",
        "recipes_vectors_path = join(main_path, 'recipes/recipes_vectors.json')\n",
        "\n",
        "# path to recipes cleared out of unnecessary ingredients\n",
        "recipes_cleared_path = join(main_path, 'recipes/recipes_cleared.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcFinfbhpIdH"
      },
      "source": [
        "## Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_LQpauEqZJZ",
        "outputId": "f627fac4-7ead-4da8-f656-d8237f0d0d8a"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J6PE5HIqIRz",
        "outputId": "abcd9a3a-e201-46f6-a96e-c22674f7204b"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "ft_path = os.path.join(main_path, 'fasttext/cc.pl.100.bin')\n",
        "ft = fasttext.load_model(ft_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY-m0LmdpTfo"
      },
      "source": [
        "## Morfeusz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mbbIxZew8C0",
        "outputId": "24e23727-a0d5-4dea-9297-3e2d9e09c7c8"
      },
      "outputs": [],
      "source": [
        "!pip install morfeusz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1YgcmSsCxHSO"
      },
      "outputs": [],
      "source": [
        "import morfeusz2\n",
        "morf = morfeusz2.Morfeusz()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lJxOPTT6LTd"
      },
      "source": [
        "## PrettyPrinter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ICnNTerz6Pnu"
      },
      "outputs": [],
      "source": [
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "0V7JW2xo6Np7"
      },
      "outputs": [],
      "source": [
        "pp = pprint.PrettyPrinter(indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Top5P9zopZgn"
      },
      "source": [
        "# Source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU8gK5QfvjnM"
      },
      "source": [
        "## Clear, lemmatize and vectorize ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nrh3jvAf15IA"
      },
      "outputs": [],
      "source": [
        "def find_all_subjects(\n",
        "    syntactic_analysis: List[\n",
        "        Tuple[int, int, Tuple[str, str, str, List[str], List[str]]]\n",
        "    ]\n",
        ") -> List[str]:\n",
        "    \"\"\"Find all subjects in syntactic analysis using the Morfeusz tags.\"\"\"\n",
        "    return [a for a in syntactic_analysis if a[2][2].split(\":\")[0] == \"subst\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VnLGtTVBylvE"
      },
      "outputs": [],
      "source": [
        "def lemmatize(word: str) -> str:\n",
        "    \"\"\"Lemmatize the word and clear the lemma of unnecessary signs.\"\"\"\n",
        "    analysis = morf.analyse(word)\n",
        "    analysis = find_all_subjects(analysis)\n",
        "    if not analysis:\n",
        "        return -1\n",
        "    lemmas = [a[2][1] for a in analysis]\n",
        "    cleared_lemmas = []\n",
        "    for lemma in lemmas:\n",
        "        if len(lemma.split(\":\")) == 1:\n",
        "            cleared_lemmas.append(lemma)\n",
        "    cleared_lemmas2 = []\n",
        "    prefs = set()\n",
        "    for lemma in cleared_lemmas:\n",
        "        if lemma[:3] not in prefs:\n",
        "            cleared_lemmas2.append(lemma)\n",
        "            prefs.add(lemma[:3])\n",
        "    return \" \".join(cleared_lemmas2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "iDUs8I63zrmn"
      },
      "outputs": [],
      "source": [
        "def remove_quantity(ingredient: str) -> str:\n",
        "    \"\"\"Remove the quantiti of ingredients from string.\n",
        "    F.e.: 'cebula 1 sztuka' -> 'cebula'\n",
        "    \"\"\"\n",
        "    words = ingredient.split()\n",
        "    for ingredient_part in words:\n",
        "        if ingredient_part.isdigit():\n",
        "            return \" \".join(words[: words.index(ingredient_part)])\n",
        "    return \" \".join(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n74XCgguxdt"
      },
      "outputs": [],
      "source": [
        "keywords_to_remove = [\"Knorr\", 'fix', \"Fix\", 'olej', 'oliwa', 'sól', 'woda', 'pieprz',\n",
        "'mąka', 'masło', 'cukier', 'ryż', 'cebula', 'null']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kSHIrM1CztxF"
      },
      "outputs": [],
      "source": [
        "def remove_some_ingredients(ingredients: List[str]) -> List[str]:\n",
        "    \"\"\"Remove unsignificant ingredients to leave only the key ones.\"\"\"\n",
        "    return [\n",
        "        ingredient\n",
        "        for ingredient in ingredients\n",
        "        if not any(k in ingredient for k in keywords_to_remove)\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "DQKMDk00I04L"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(ingredient: str) -> str:\n",
        "  \"\"\"Remove stopwords from ingredient.\n",
        "  F.e.: for ingredient: 'sól null' -> sól\n",
        "  \"\"\"\n",
        "  stop_words = ['null']\n",
        "  ingredient = [i for i in ingredient.split(' ') if i not in stop_words]\n",
        "  return ' '.join(ingredient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "jexS8hj7wQoB"
      },
      "outputs": [],
      "source": [
        "def clear_recipes() -> None:\n",
        "    \"\"\"Clear recipes and theirs ingredients in order to be searchable.\"\"\"\n",
        "    cleared_recipes_dict = {}\n",
        "    with open(recipes_path, \"r\", encoding=\"utf-8\") as recipe_file:\n",
        "        recipes = json.load(recipe_file)\n",
        "        for url, recipe in recipes.items():\n",
        "            try:\n",
        "                ingredients = recipe[\"ingredients\"]\n",
        "                instructions = recipe[\"instructions\"]\n",
        "                title = recipe[\"title\"]\n",
        "            except KeyError:\n",
        "                continue\n",
        "            ingredients_without_stopwords = list(map(remove_stopwords, ingredients))\n",
        "            cleared_ingredients = list(map(remove_quantity, ingredients))\n",
        "            cleared_ingredients = remove_some_ingredients(cleared_ingredients)\n",
        "            cleared_ingredients = [word for word in cleared_ingredients if word]\n",
        "            cleared_ingredients = list(map(lemmatize, cleared_ingredients))\n",
        "            if not any(i == -1 for i in cleared_ingredients):\n",
        "                cleared_recipes_dict[url] = {\n",
        "                    \"title\": title,\n",
        "                    \"instructions\": instructions,\n",
        "                    \"ingredients\": ingredients_without_stopwords,\n",
        "                    \"ingredients_cleared\": cleared_ingredients,\n",
        "                }\n",
        "    with open(recipes_cleared_path, \"w\", encoding=\"utf-8\") as cleared_file:\n",
        "        json.dump(cleared_recipes_dict, cleared_file, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8kdhghf5Iyz"
      },
      "outputs": [],
      "source": [
        "word_vectors_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "WgZJ0-T_wdNg"
      },
      "outputs": [],
      "source": [
        "def get_sentence_vector(sentence: str) -> float:\n",
        "    \"\"\"Split the sentence into words, get rid of special signs and\n",
        "    use fasttext to get their vector representation.\n",
        "    Fill the word_vectors_dict to speed up the process in the future.\n",
        "\n",
        "    The vector of the sentence is the sum of vectors of words\n",
        "    divided by the number of words.\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    words_without_special_signs = [re.sub(r\"[\\W_]+\", \"\", word) for word in words]\n",
        "\n",
        "    word_vectors = []\n",
        "    for word in words_without_special_signs:\n",
        "        if word not in word_vectors_dict:\n",
        "            word_vectors_dict[word] = ft.get_word_vector(word)\n",
        "        word_vectors.append(word_vectors_dict[word])\n",
        "\n",
        "    word_vectors = list(map(np.array, word_vectors))\n",
        "    vectors_sum = np.add.reduce(word_vectors)\n",
        "    return vectors_sum / len(words_without_special_signs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E5mTJK-mwfQ9"
      },
      "outputs": [],
      "source": [
        "def find_cosine_similarity(vector_A: float, vector_B: float) -> np.ndarray:\n",
        "    \"\"\"Calculate cosine similarity for two vectors.\"\"\"\n",
        "    return np.dot(vector_A, vector_B) / (\n",
        "        np.linalg.norm(vector_A) * np.linalg.norm(vector_B)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8mw2Xc3Kwp9-"
      },
      "outputs": [],
      "source": [
        "def make_ingredients_vector_file() -> None:\n",
        "    \"\"\"Get cleared recipes and vectors and create ingredients vectors file.\"\"\"\n",
        "    with open(recipes_cleared_path, \"r\", encoding=\"utf-8\") as recipe_file:\n",
        "        with open(recipes_vectors_path, \"w\", encoding=\"utf-8\") as vectors_file:\n",
        "            recipes = json.load(recipe_file)\n",
        "            for url, recipe in recipes.items():\n",
        "                try:\n",
        "                    ingredients = recipe[\"ingredients_cleared\"]\n",
        "                except KeyError:\n",
        "                    continue\n",
        "                ingredients_vector = get_sentence_vector(\" \".join(ingredients))\n",
        "                try:\n",
        "                    ingredients_vector = ingredients_vector.tolist()\n",
        "                    ingredients_vector = [round(num, 4) for num in ingredients_vector]\n",
        "                    to_write = json.dumps({url: ingredients_vector}, ensure_ascii=False)\n",
        "                    vectors_file.write(f\"{to_write}\\n\")\n",
        "                except:\n",
        "                    continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aS8J2yiXEmo"
      },
      "source": [
        "## Find recipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "21ZQ-B24rpRc"
      },
      "outputs": [],
      "source": [
        "def get_urls_of_recipes(ingredients: str) -> List[str]:\n",
        "    \"\"\"Get url adresses of recipes.\"\"\"\n",
        "    ingredients = ingredients.split(\",\")\n",
        "    ingredients = \" \".join(list(map(lemmatize, ingredients)))\n",
        "    vector_in = get_sentence_vector(ingredients)\n",
        "    res_urls = {}\n",
        "    with open(recipes_vectors_path, \"r\", encoding=\"utf8\") as vectors:\n",
        "        for line in vectors:\n",
        "            ((url_out, vector_out),) = json.loads(line).items()\n",
        "            similarity = find_cosine_similarity(vector_in, vector_out)\n",
        "            res_urls[url_out] = similarity\n",
        "    return sorted(res_urls, key=res_urls.get, reverse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "aXf8NhYQrXpg"
      },
      "outputs": [],
      "source": [
        "def find_recipes(\n",
        "    ingredients: str, how_many: int = 1\n",
        ") -> List[Dict[str, Union[str, List[str]]]]:\n",
        "    \"\"\"Find recipes in a file that match given ingredients.\"\"\"\n",
        "    urls = get_urls_of_recipes(ingredients)\n",
        "    recipes_out = []\n",
        "    with open(recipes_cleared_path, \"r\") as recipes_file:\n",
        "        recipes = json.load(recipes_file)\n",
        "        for url in urls:\n",
        "            if url in recipes.keys():\n",
        "                recipes_out.append(recipes[url])\n",
        "    return recipes_out[:how_many]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "dS64761AaHHk"
      },
      "outputs": [],
      "source": [
        "def find_best_recipe(ingredients: List[str]) -> str:\n",
        "    \"\"\"Find 3 best recipes and then chose randomly one of them.\"\"\"\n",
        "    three_tries = find_recipes(ingredients, 3)\n",
        "    random_of_best = random.choice(three_tries)\n",
        "    return f\"{random_of_best['title']}.\\nSkładniki:\\n{', '.join(random_of_best['ingredients'])}.\\nInstrukcje:\\n{random_of_best['instructions']}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0zZKQBvcomYs",
        "outputId": "a62be1a6-afba-4759-9427-a00cc8aca070"
      },
      "outputs": [],
      "source": [
        "find_best_recipe(\"szynka, ser, ogórek, majonez, makaron\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Z0XQt0LOtXRc",
        "outputId": "f2a87a5d-caf7-4a6c-a915-f3c0172b6628"
      },
      "outputs": [],
      "source": [
        "find_best_recipe(\"małże, pomidory\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "find_recipes.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2d88b3436f126e5ca958fe744d6b1733d9ae2d76f94be1319c644c47ba23c26f"
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
