{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNbBpj4-5TWs"
      },
      "source": [
        "# Prerequisities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdN7AeKz5bsR",
        "outputId": "b8479b89-8d0a-4c7f-88b9-2c80f104636e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "W69CY1BP09Eu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "from operator import itemgetter\n",
        "import string\n",
        "from typing import Dict, List, Set, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "i86lsTWDuCTC"
      },
      "outputs": [],
      "source": [
        "# main path to your data folder\n",
        "main_path = 'gdrive/MyDrive/bot/data'\n",
        "\n",
        "# path to fasttext vectors file\n",
        "ft_path = os.path.join(main_path, 'fasttext/cc.pl.100.bin')\n",
        "\n",
        "# path to vectors generated from open_subtitles\n",
        "vectors_path = os.path.join(main_path, 'open_subtitles/1MB_vectors')\n",
        "\n",
        "# path to a dictionary that is build from corpora and consists from pairs: \"word\": [nr_of_line, another_nr_of_line, ...]\n",
        "index_dict_path = os.path.join(main_path, 'sentence_similarity/index_dict2.json')\n",
        "\n",
        "# path to the corpora with only the most popular words\n",
        "corpus_with_populars_path = os.path.join(main_path, 'sentence_similarity/corpus_with_populars2.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZgS1-fOkSOz"
      },
      "source": [
        "## Fastext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMl_b6At5MPJ",
        "outputId": "7f9e8140-fe51-4bea-e6b2-c4a037e7768e"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "ZdAKFku28QcY"
      },
      "outputs": [],
      "source": [
        "import fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYAX8YOYBcA2",
        "outputId": "e38992d5-3c0f-4d64-bca4-24aaac2003fb"
      },
      "outputs": [],
      "source": [
        "ft = fasttext.load_model(ft_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sCBWeHMkY1X"
      },
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mHT6jEahI_Z",
        "outputId": "075e9bde-ebb0-4797-e9b0-79c5d0638115"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "x2fkw1-MiXPh"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BertForMaskedLM\n",
        "from transformers import BertTokenizer\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "_B-fGm1DB0It"
      },
      "outputs": [],
      "source": [
        "def get_pred_model():\n",
        "    \"\"\"Get Bert model ready for usage.\"\"\"\n",
        "    model = BertForMaskedLM.from_pretrained(\"allegro/herbert-large-cased\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")\n",
        "    pred_pipeline = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "    return pred_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsKO2PHiB1wE",
        "outputId": "9385386a-a91f-403f-b311-bb6ee18f0ba8"
      },
      "outputs": [],
      "source": [
        "bert_model = get_pred_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMMZBxpmkddf"
      },
      "source": [
        "## Morfeusz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CigIlyDxkBQy",
        "outputId": "400ff31c-26c1-46c0-9dee-e34952abc3a7"
      },
      "outputs": [],
      "source": [
        "!pip install morfeusz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "KiDwiIfMkGiN"
      },
      "outputs": [],
      "source": [
        "import morfeusz2\n",
        "morf = morfeusz2.Morfeusz()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwImNXHB8kwM"
      },
      "source": [
        "# Source sentence_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "OwOilE0R6-4_"
      },
      "outputs": [],
      "source": [
        "word_vectors_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "9axCfOUf6eIi"
      },
      "outputs": [],
      "source": [
        "def get_sentence_vector(sentence: str) -> float:\n",
        "    \"\"\"Split the sentence into words, get rid of special signs and \n",
        "    use fasttext to get their vector representation. \n",
        "    Fill the word_vectors_dict to speed up the process in the future.\n",
        "\n",
        "    The vector of the sentence is the sum of vectors of words \n",
        "    divided by the number of words.\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    words_without_special_signs = [\n",
        "        re.sub(r'[\\W_]+', '', word) for word in words]\n",
        "\n",
        "    word_vectors = []\n",
        "    for word in words_without_special_signs:\n",
        "        if word not in word_vectors_dict:\n",
        "            word_vectors_dict[word] = ft.get_word_vector(word)\n",
        "        word_vectors.append(word_vectors_dict[word])\n",
        "\n",
        "    word_vectors = list(map(np.array, word_vectors))\n",
        "    vectors_sum = np.add.reduce(word_vectors)\n",
        "    return vectors_sum / len(words_without_special_signs)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EdJIRaYAhccz"
      },
      "outputs": [],
      "source": [
        "def read_indexes_dict() -> Dict[str, List[int]]:\n",
        "    \"\"\"Read indexes dict from a json file.\"\"\"\n",
        "    with open(index_dict_path, \"r\", encoding=\"utf-8\") as indexes:\n",
        "        index_dict = json.load(indexes)\n",
        "    return index_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "maH1dW1qiSHK"
      },
      "outputs": [],
      "source": [
        "index_dict = read_indexes_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Kztmy7-tx8w4"
      },
      "outputs": [],
      "source": [
        "def load_corpus_line_offset() -> List[int]:\n",
        "    \"\"\"Read the corpus with popular words once and build\n",
        "       a list of line offsets.\n",
        "    \"\"\"\n",
        "    with open(corpus_with_populars_path, \"rb\") as corpus:\n",
        "        line_offset = []\n",
        "        offset = 0\n",
        "        for line in corpus:\n",
        "            line_offset.append(offset)\n",
        "            offset += len(line)\n",
        "        corpus.seek(0)\n",
        "    return line_offset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "X_yk0huS2bH0"
      },
      "outputs": [],
      "source": [
        "line_offset = load_corpus_line_offset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eeQD328C6kh0"
      },
      "outputs": [],
      "source": [
        "def find_cosine_similarity(vector_A: float, vector_B: float) -> np.ndarray:\n",
        "    \"\"\"Calculate cosine similarity for two vectors.\"\"\"\n",
        "    return np.dot(vector_A, vector_B) / (\n",
        "        np.linalg.norm(vector_A) * np.linalg.norm(vector_B)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "E5vIUIhoGjao"
      },
      "outputs": [],
      "source": [
        "def get_synonyms_with_weights(word: str) -> Tuple[List[str], List[float]]:\n",
        "    \"\"\"Get synonyms of given word using fasttext.\"\"\"\n",
        "    neighbours = ft.get_nearest_neighbors(word, k=5)\n",
        "    synonyms = [x[1] for x in neighbours]\n",
        "    synonyms = [\n",
        "        x.translate(str.maketrans(\"\", \"\", string.punctuation)) for x in synonyms\n",
        "    ]\n",
        "    weights = [x[0] for x in neighbours]\n",
        "    return synonyms, weights\n",
        "\n",
        "\n",
        "def get_all_synonyms(word: str) -> List[str]:\n",
        "    \"\"\"Get all synonyms of a word\"\"\"\n",
        "    return get_synonyms_with_weights(word)[0]\n",
        "\n",
        "\n",
        "def get_best_synonym(word: str) -> str:\n",
        "    \"\"\"Determine which synonym has the biggest score and return it.\"\"\"\n",
        "    synonyms, weights = get_synonyms_with_weights(word)\n",
        "    index = weights.index(max(weights))\n",
        "    return synonyms[index]\n",
        "\n",
        "\n",
        "def get_random_synonym(word: str) -> str:\n",
        "    \"\"\"Get random synonym from list of synonyms generated with fasttext.\"\"\"\n",
        "    return random.choice(get_all_synonyms(word))\n",
        "\n",
        "\n",
        "def get_synonyms_for_all_sentence(words: List[str]) -> Set[str]:\n",
        "    \"\"\"Get synonyms for all words in the sentence packed in the 'words' list.\"\"\"\n",
        "    all_sentence_synonyms = []\n",
        "    for word in words:\n",
        "        all_sentence_synonyms += get_all_synonyms(word)\n",
        "    return set(all_sentence_synonyms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FA5pdWKh6rxU"
      },
      "outputs": [],
      "source": [
        "def similarity_by_embeddings(input_message: str, words: List[str]) -> str:\n",
        "    \"\"\"Find best answer in the corpora using cosine similarity \n",
        "    between input message and lines from corpora.\n",
        "    \"\"\"\n",
        "    mini_index_dict = {}\n",
        "    words = get_synonyms_for_all_sentence(words)\n",
        "    for word in words:\n",
        "        if word in index_dict:\n",
        "            mini_index_dict[word] = set(index_dict[word])\n",
        "    corpora_sentences = load_lines_from_corpora(mini_index_dict)\n",
        "    input_message_vector = get_sentence_vector(input_message)\n",
        "    sentence2cosine_similarity = {}\n",
        "    for sentence in corpora_sentences:\n",
        "        sentence2cosine_similarity[sentence] = find_cosine_similarity(\n",
        "            input_message_vector, get_sentence_vector(sentence)\n",
        "        )\n",
        "    sorted_sentence2cosine_similarity = {\n",
        "        k: v\n",
        "        for k, v in sorted(\n",
        "            sentence2cosine_similarity.items(), key=lambda item: item[1], reverse=True\n",
        "        )\n",
        "    }\n",
        "    best_answer = list(sorted_sentence2cosine_similarity.keys())[0]\n",
        "    return best_answer\n",
        "\n",
        "\n",
        "def load_lines_from_corpora(mini_index_dict: Dict[str, List[int]]) -> Set[str]:\n",
        "    \"\"\"Load lines of found indexes from corpora.\"\"\"\n",
        "    corpora_sentences = set()\n",
        "    with open(corpus_with_populars_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        for indexes in mini_index_dict.values():\n",
        "            for line_number in indexes:\n",
        "                file.seek(line_offset[line_number])\n",
        "                try:\n",
        "                    corpora_sentences.add(file.readline())\n",
        "                except:\n",
        "                    continue\n",
        "    return corpora_sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H2P1K2VBus9P",
        "outputId": "fb975f40-f145-42fc-a2e0-2fdd104e8f5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Naprawdę lubisz czytać komiksy !\\n'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarity_by_embeddings(\n",
        "    \"Bardzo lubię czytać czasopisma\", [\"lubię\", \"czytać\", \"czasopisma\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70wU8izGet4j"
      },
      "source": [
        "# Source word_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Wkq1f-FWiftg"
      },
      "outputs": [],
      "source": [
        "def find_all_subjects_and_verbs(sentence: str) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"Find subjects and verbs in a sentence using Morfeusz analysis.\"\"\"\n",
        "    analysis = morf.analyse(sentence)\n",
        "    subjects, verbs = [], []\n",
        "    verbs_tags = [\n",
        "        \"verb\",\n",
        "        \"refl\",\n",
        "        \"nonrefl\",\n",
        "        \"perf\",\n",
        "        \"imperf\",\n",
        "        \"imperf.perf\",\n",
        "        \"praet\",\n",
        "        \"inf\",\n",
        "        \"fin\",\n",
        "    ]\n",
        "    for i, j, interp in analysis:\n",
        "        first_tag = interp[2].split(\":\")[0]\n",
        "        if first_tag == \"subst\":\n",
        "            subjects.append(interp[0])\n",
        "        elif first_tag in verbs_tags:\n",
        "            verbs.append(interp[1])\n",
        "    return subjects, verbs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "5ly2YBTARjLk"
      },
      "outputs": [],
      "source": [
        "def get_first_person(verb: str) -> str:\n",
        "    \"\"\"Take verb and find its form for the first person singular.\"\"\"\n",
        "    generated_verbs = morf.generate(verb)\n",
        "    for elem in generated_verbs:\n",
        "        if \"sg\" in elem[2] and \"pri\" in elem[2]:\n",
        "            return elem[0]\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "xmiROsXz__YW"
      },
      "outputs": [],
      "source": [
        "def get_noun_and_verb(sentence: str) -> Tuple[str, str]:\n",
        "    \"\"\"Get random noun and verb calculated from given sentence.\"\"\"\n",
        "    nouns, verbs = find_all_subjects_and_verbs(sentence)\n",
        "    verbs_first = list(map(get_first_person, verbs))\n",
        "    nouns_synonyms = list(map(get_random_synonym, nouns))\n",
        "    if nouns_synonyms:\n",
        "        random_noun = random.choice(nouns_synonyms)\n",
        "    else:\n",
        "        random_noun = \".\"\n",
        "    if verbs_first:\n",
        "        random_verb = random.choice(verbs_first)\n",
        "    else:\n",
        "        random_verb = \"jestem\"\n",
        "    return random_noun, random_verb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "4OWfHScv36VK"
      },
      "outputs": [],
      "source": [
        "def generate_answer(sentence: str) -> str:\n",
        "    \"\"\"Generate answer using Bert model and synonyms and verbs in first person singular.\"\"\"\n",
        "    noun, verb = get_noun_and_verb(sentence)\n",
        "    first_gen = bert_model(f\"{verb} {bert_model.tokenizer.mask_token} {noun}\")[0][\"sequence\"]\n",
        "    second_gen = bert_model(f\"{bert_model.tokenizer.mask_token} {first_gen}\")[1][\"sequence\"]\n",
        "    third_gen = bert_model(f\"{second_gen} {bert_model.tokenizer.mask_token}.\")[0][\"sequence\"]\n",
        "    return third_gen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u0rqNl_94GLI",
        "outputId": "a20f6d22-2acf-4ee0-de4c-0839d636358d"
      },
      "outputs": [],
      "source": [
        "generate_answer(\"Czy lubisz jeść czekoladę?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FUs_K2dAybW1",
        "outputId": "fa0723a9-3129-48f4-d4d4-ed07242d21d1"
      },
      "outputs": [],
      "source": [
        "generate_answer(\"Czy chciałbyś umieć latać?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Vh5N4bX0ZqXe",
        "outputId": "cf31b558-7530-4651-97c1-f024000ab82a"
      },
      "outputs": [],
      "source": [
        "generate_answer(\"Gdzie jedziesz na wakacje?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1wlp0U6qmNH7",
        "outputId": "7a7c2217-8a55-4a02-dc95-5fcd5a211ec4"
      },
      "outputs": [],
      "source": [
        "generate_answer(\"O której się budzisz?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sentence_similarity.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "56c55f9ad07450a335c9416900c5604cd7caa387778db699d09978d0d3cda72f"
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
